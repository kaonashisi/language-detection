{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3448352a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sirinekefi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FB_HEIGHT = 40  # filter banks\n",
    "WIDTH = 1000\n",
    "COLOR_DEPTH = 1\n",
    "INPUT_SHAPE = (FB_HEIGHT, WIDTH, COLOR_DEPTH)\n",
    "\n",
    "DATA_TYPE = 'float32'\n",
    "DATA_KEY = 'data'\n",
    "\n",
    "LANGUAGES = ['en', 'de', 'es']\n",
    "GENDERS = ['m', 'f']\n",
    "\n",
    "LANGUAGE_INDEX = 0\n",
    "GENDER_INDEX = 1\n",
    "\n",
    "THRESHOLD = 0.8\n",
    "\n",
    "FRAGMENT_DURATION = 10  # seconds\n",
    "\n",
    "DATASET_DIST = '../build'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67167d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "# supress all warnings (especially matplotlib warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# RANDOMNESS\n",
    "# https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
    "# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# disable auto tune\n",
    "# https://github.com/tensorflow/tensorflow/issues/5048\n",
    "os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.random.set_seed(SEED)\n",
    "sess = tf.compat.v1.Session()\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten\n",
    "from keras.layers import Dropout, Input, Activation\n",
    "from keras.optimizers import Nadam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2467d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc52a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 40x1000\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        16,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_regularizer=regularizers.l2(0.001),\n",
    "        input_shape=input_shape))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # 20x500\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # 10x250\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # 5x125\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        128,\n",
    "        (3, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 5), strides=(1, 5), padding='same'))\n",
    "\n",
    "    # 5x25\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        256,\n",
    "        (3, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 5), strides=(1, 5), padding='same'))\n",
    "    model.add(AveragePooling2D(\n",
    "        pool_size=(5, 5),\n",
    "        strides=(5, 5),\n",
    "        padding='valid'))\n",
    "\n",
    "    # 1x1\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(\n",
    "        32,\n",
    "        activation='elu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(len(LANGUAGES)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.0, nesterov=False)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=sgd,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c7aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(labels, features, metadata, model, clazzes, title=\"test\"):\n",
    "    probabilities = model.predict(features, verbose=0)\n",
    "\n",
    "    expected = flatten(labels)\n",
    "    actual = flatten(probabilities)\n",
    "\n",
    "    print(\"\\n## {title}\\n\".format(title=title))\n",
    "\n",
    "    max_probabilities = np.amax(probabilities, axis=1)\n",
    "\n",
    "    print(\"Average confidence: {average}\\n\".format(\n",
    "        average=np.mean(max_probabilities)))\n",
    "\n",
    "    errors = pd.DataFrame(np.zeros((len(clazzes), len(GENDERS)), dtype=int),\n",
    "                          index=clazzes, columns=GENDERS)\n",
    "    threshold_errors = pd.DataFrame(\n",
    "        np.zeros((len(clazzes), len(GENDERS)), dtype=int),\n",
    "        index=clazzes,\n",
    "        columns=GENDERS)\n",
    "    threshold_scores = pd.DataFrame(\n",
    "        np.zeros((len(clazzes), len(GENDERS)), dtype=int),\n",
    "        index=clazzes,\n",
    "        columns=GENDERS)\n",
    "    for index in range(len(actual)):\n",
    "        clazz = metadata[index][LANGUAGE_INDEX]\n",
    "        gender = metadata[index][GENDER_INDEX]\n",
    "        if actual[index] != expected[index]:\n",
    "            errors[gender][clazz] += 1\n",
    "        if actual[index] >= THRESHOLD:\n",
    "            if actual[index] != expected[index]:\n",
    "                threshold_errors[gender][clazz] += 1\n",
    "            if actual[index] == expected[index]:\n",
    "                threshold_scores[gender][clazz] += 1\n",
    "\n",
    "    print(\"Amount of errors by gender:\")\n",
    "    print(errors, \"\\n\")\n",
    "    print(\"Amount of errors by gender (threshold {0}):\".format(THRESHOLD))\n",
    "    print(threshold_errors, \"\\n\")\n",
    "    print(\"Amount of scores by gender (threshold {0}):\".format(THRESHOLD))\n",
    "    print(threshold_scores, \"\\n\")\n",
    "\n",
    "    print(classification_report(expected, actual, target_names=clazzes))\n",
    "\n",
    "def load_data(label_binarizer, input_dir, group, fold_indexes, input_shape):\n",
    "    all_metadata = []\n",
    "    all_features = []\n",
    "    \n",
    "    print(\"\\n\")\n",
    